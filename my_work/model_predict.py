# -*- coding: utf-8 -*-
"""model_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sjLkI-m7lAl1tnhKntGHj1_rN3JMroMh
"""

mapping={
0: 'ट',1:'ड', 2:'ढ', 3: 'त', 4: 'थ',
5: 'ध', 6: 'न', 7: 'प', 8: 'भ', 9:'म',
10: 'र', 11: 'ल', 12: 'व', 13:'स', 14: 'ह',
15:'क्ष', 16:'त्र', 17:'ज'
}

# pip install opencv-contrib-python

import cv2 as cv
import tensorflow
from tensorflow import keras
from tensorflow.keras.models import load_model
import numpy as np
from collections import deque
import pandas as pd
import matplotlib.pyplot as plt
# model = load_model('../input/mymodel/f_model.h5')

model = load_model('model_out.h5')

def contours_list(img):
  
    # plt.imshow(img)
    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)

    ret, thresh = cv.threshold(gray, 125, 255, cv.THRESH_BINARY)
    #cv.imshow('Thresh', thresh)  # binary image
    #cv.imwrite('threshhiks.jpeg',thresh)

    myArray = np.array(thresh)
    myArray_sum =255-myArray  # convert background black and text white

    #ye filter wala part hai
    componentsNumber, labeledImage, componentStats, componentCentroids = \
        cv.connectedComponentsWithStats(myArray_sum, connectivity=4)

    # Set the minimum pixels for the area filter:
    minArea = min(img.shape[0],img.shape[1])/6
    #print(minArea)


    remainingComponentLabels = [i for i in range(1, componentsNumber) if componentStats[i][4] >= minArea]

    filteredImage = np.where(np.isin(labeledImage, remainingComponentLabels) == True, 255, 0).astype('uint8')


    inputCopy = filteredImage.copy()
    


    #countour dhoondna

    contours, hierarchy = cv.findContours(filteredImage, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)

    contours_poly = [None] * len(contours)
    boundRect = []


    #print(len(contours))
    max_square=0
    indx=0
    for i in range(len(contours)):
        cnt=contours[i]
        area=cv.contourArea(cnt)
        if area>max_square :
            max_square=area
            indx=i
    #print(indx)
    rect = cv.minAreaRect(contours[indx])

    angle = rect[2]

    # print(angle)

    rows,cols = filteredImage.shape[0], filteredImage.shape[1]

    M = cv.getRotationMatrix2D((cols/2,rows/2),angle-90,1)

    img_rot = cv.warpAffine(filteredImage,M,(cols,rows))
    #cv.imwrite('ashg.jpeg',img_rot)

    rect0 = (rect[0], rect[1], 0.0)
    box = cv.boxPoints(rect)
    pts = np.int0(cv.transform(np.array([box]), M))[0]
    pts[pts < 0] = 0

    #cv.drawContours(img_rot,[pts],0,(255,0,255),2)
    #cv.imwrite('ahg.jpeg',img_rot)
    #print(pts)
    #print(pts[3][0])
    wordg =img_rot[pts[1][1]:pts[2][1],
                          pts[0][0]:pts[1][0]]
    
    # plt.imshow(wordg)

    if wordg.shape[0]>wordg.shape[1]:
        word = cv.rotate(wordg, cv.cv2.ROTATE_90_COUNTERCLOCKWISE)
    else :
        word =wordg
    # cv.imwrite('final_word.jpeg',word)



    height = word.shape[0]
    width = word.shape[1]
    #print(height,width)
    tmp_array = word
    # plt.imshow(tmp_array)
    idx = -1
    max=0
    h=int(height/2)
    for i in range(0, h):
        sum = 0
        for j in range(0, width):
            sum += word[i][j]
            if sum>max:
              max=sum
              idx=i
            #if sum > 0:  # header line found
            #idx = i
            #break
    heigh=int(height/8)
    for i in range(idx -heigh,idx+heigh):
        for j in range(0, width):
            tmp_array[i][j] = 0  # make that line merge with the babckground

    # plt.imshow(tmp_array)





    #countour dhoondna

    contours, hierarchy = cv.findContours(tmp_array, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)

    contours_poly = [None] * len(contours)
    boundRect = []

    #bounding boxes dhoondna
    for i, c in enumerate(contours):

        if hierarchy[0][i][3] == -1:
            contours_poly[i] = cv.approxPolyDP(c, 3, True)
            boundRect.append(cv.boundingRect(contours_poly[i]))
    shak=tmp_array.copy()
    for i in range(len(boundRect)):
        color = (230, 0, 0)
        cv.rectangle(shak, (int(boundRect[i][0]-10), int(boundRect[i][1]-10)), \
                      (int(boundRect[i][0] + boundRect[i][2]+10), int(boundRect[i][1] + boundRect[i][3]+10)), color, 2)
    # cv.imwrite('cont.jpeg',shak)

    # Crop karna
    
    # print(len(boundRect))
    cv.imshow('img',word)
    cv.waitKey(0)
    boundRect.sort()
    imagearr=[]
    for i in range(len(boundRect)):
          x, y, w, h = boundRect[i]


          croppedImg = word[y:y + h, x:x + w]
          # if i==1:

          #   plt.imshow(croppedImg)
          croppedImg = cv.resize(croppedImg, (64, 64))
          croppedImg = np.reshape(croppedImg, (-1, 64, 64, 1))
          imagearr.append(croppedImg)
            #print(boundRect[i][1]-boundRect[i][3])
            # if abs(boundRect[i][1]-boundRect[i][3])>min(height,width)/20:
                #print(min(height, width) / 6)

                          
                #cv.imshow("Cropped Character: "+str(i), croppedImg)
                #cv.waitKey(1000)
    return imagearr

def predict(img):
    
    
    characters_list=contours_list(img)
    cv.imshow('img',characters_list[0][0])
    cv.waitKey(100)
    final_output_list=[]
    for i in range(len(characters_list)):
        pred_probab = model.predict(characters_list[i])[0]
        pred_class = list(pred_probab).index(max(pred_probab))
        # print(pred_class,end=' ')
        final_output_list.append(pred_class)
        # plt.imshow(characters_list[i][0])
   
    
    return final_output_list


img=cv.imread('mal.jpeg')
# cv.imshow('img',img)
# cv.waitKey(100)
fans=predict(img)
for i in range(len(fans)):
    print(fans[i],' ')





